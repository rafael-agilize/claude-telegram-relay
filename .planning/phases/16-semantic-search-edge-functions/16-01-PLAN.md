---
phase: 16-semantic-search-edge-functions
plan: 01
type: execute
wave: 1
depends_on: ["15-01"]
files_modified:
  - src/relay.ts
  - supabase/functions/embed/index.ts
  - supabase/functions/search/index.ts
  - examples/supabase-schema-v2.sql
  - docs/SETUP-SEMANTIC-SEARCH.md
autonomous: true

must_haves:
  truths:
    - "supabase/functions/embed/index.ts exists — Deno Edge Function that receives a global_memory row, generates OpenAI text-embedding-3-small vector, and updates the row's embedding column"
    - "supabase/functions/search/index.ts exists — Deno Edge Function that receives a query string, generates its embedding, calls match_memory() RPC, and returns ranked results"
    - "getRelevantMemory(query) function exists in relay.ts — calls search Edge Function via supabase.functions.invoke(), returns array of relevant memories, returns empty array on any error"
    - "buildPrompt() includes a RELEVANT MEMORIES section when semantic results are available"
    - "RELEVANT MEMORIES section is deduplicated against facts and active goals already shown in the prompt"
    - "System works fully without Edge Functions deployed — getRelevantMemory() fails silently and returns []"
    - "OpenAI API key is only in Supabase Edge Function secrets — no new env vars in relay .env"
    - "All relay changes are in src/relay.ts — single-file architecture preserved"
  artifacts:
    - path: "supabase/functions/embed/index.ts"
      provides: "Auto-embedding Edge Function for global_memory inserts"
      contains: "text-embedding-3-small"
    - path: "supabase/functions/search/index.ts"
      provides: "Semantic search Edge Function using match_memory() RPC"
      contains: "match_memory"
    - path: "src/relay.ts"
      provides: "getRelevantMemory() function and buildPrompt() integration"
      contains: "getRelevantMemory"
    - path: "docs/SETUP-SEMANTIC-SEARCH.md"
      provides: "Setup instructions for Edge Functions, secrets, and webhook"
      contains: "OPENAI_API_KEY"
  key_links:
    - from: "Database webhook (INSERT on global_memory)"
      to: "supabase/functions/embed/index.ts"
      via: "Supabase Dashboard webhook or pg_net trigger"
      pattern: "INSERT triggers embed function"
    - from: "getRelevantMemory()"
      to: "supabase/functions/search/index.ts"
      via: "supabase.functions.invoke('search')"
      pattern: "supabase.functions.invoke('search'"
    - from: "buildPrompt()"
      to: "getRelevantMemory()"
      via: "fetches relevant memories for the user message"
      pattern: "getRelevantMemory(userMessage)"
    - from: "supabase/functions/search/index.ts"
      to: "match_memory() RPC"
      via: "Supabase RPC call with query embedding"
      pattern: "supabase.rpc('match_memory'"
---

<objective>
Add semantic search to the relay by creating two Supabase Edge Functions (auto-embed on INSERT, semantic search on query) and integrating the search results into the prompt context.

Purpose: Phase 14 added the vector column and match_memory() RPC. Phase 15 upgraded the intent system. This phase completes v1.3 by wiring semantic search end-to-end: new memories get auto-embedded, and every user message triggers a semantic lookup that adds contextually relevant memories to the prompt.
Output: Two Supabase Edge Functions, updated relay.ts with getRelevantMemory() + buildPrompt() integration, setup documentation.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/14-schema-migration-typed-memory/14-01-PLAN.md
@.planning/phases/15-intent-system-upgrade/15-01-PLAN.md
@examples/supabase-schema-v2.sql
@src/relay.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create embed Edge Function</name>
  <files>supabase/functions/embed/index.ts</files>
  <action>
Create the directory `supabase/functions/embed/` and write `index.ts`. This Edge Function auto-embeds a `global_memory` row using OpenAI's text-embedding-3-small model. It's triggered by a Supabase database webhook on INSERT.

**Create `supabase/functions/embed/index.ts`:**

```typescript
import "jsr:@supabase/functions-js/edge-runtime.d.ts";
import { createClient } from "jsr:@supabase/supabase-js@2";

const supabaseUrl = Deno.env.get("SUPABASE_URL")!;
const supabaseKey = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY")!;
const openaiKey = Deno.env.get("OPENAI_API_KEY")!;

const supabase = createClient(supabaseUrl, supabaseKey);

Deno.serve(async (req) => {
  if (req.method !== "POST") {
    return new Response("Method not allowed", { status: 405 });
  }

  try {
    const payload = await req.json();

    // Database webhook sends: { type: "INSERT", record: { id, content, ... } }
    // Direct invocation sends: { id, content }
    const record = payload.record || payload;

    if (!record.id || !record.content) {
      return new Response(
        JSON.stringify({ error: "Missing id or content" }),
        { status: 400, headers: { "Content-Type": "application/json" } }
      );
    }

    // Skip if embedding already exists (idempotency)
    if (record.embedding) {
      return new Response(
        JSON.stringify({ skipped: true, reason: "embedding already exists" }),
        { status: 200, headers: { "Content-Type": "application/json" } }
      );
    }

    // Generate embedding via OpenAI
    const embeddingResponse = await fetch(
      "https://api.openai.com/v1/embeddings",
      {
        method: "POST",
        headers: {
          Authorization: `Bearer ${openaiKey}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          model: "text-embedding-3-small",
          input: record.content,
        }),
      }
    );

    if (!embeddingResponse.ok) {
      const err = await embeddingResponse.text();
      console.error("OpenAI API error:", err);
      return new Response(
        JSON.stringify({ error: "OpenAI API error", details: err }),
        { status: 502, headers: { "Content-Type": "application/json" } }
      );
    }

    const embeddingData = await embeddingResponse.json();
    const embedding = embeddingData.data?.[0]?.embedding;

    if (!embedding) {
      return new Response(
        JSON.stringify({ error: "No embedding returned from OpenAI" }),
        { status: 502, headers: { "Content-Type": "application/json" } }
      );
    }

    // Update the row with the generated embedding
    const { error: updateError } = await supabase
      .from("global_memory")
      .update({ embedding: JSON.stringify(embedding) })
      .eq("id", record.id);

    if (updateError) {
      console.error("Supabase update error:", updateError);
      return new Response(
        JSON.stringify({ error: "Database update failed", details: updateError.message }),
        { status: 500, headers: { "Content-Type": "application/json" } }
      );
    }

    console.log(`Embedded memory ${record.id}: "${record.content.substring(0, 50)}..."`);

    return new Response(
      JSON.stringify({ success: true, id: record.id }),
      { status: 200, headers: { "Content-Type": "application/json" } }
    );
  } catch (err) {
    console.error("Embed function error:", err);
    return new Response(
      JSON.stringify({ error: err instanceof Error ? err.message : "Unknown error" }),
      { status: 500, headers: { "Content-Type": "application/json" } }
    );
  }
});
```

**Key design decisions:**
- Uses raw `fetch` for OpenAI API (no npm dependency needed in Deno)
- Passes embedding as `JSON.stringify(embedding)` which Supabase handles for pgvector
- Idempotency check: skips if embedding already exists
- Database webhook payload format: `{ type, table, record, schema, old_record }`
- Also handles direct invocation format: `{ id, content }`
  </action>
  <verify>
1. File exists at `supabase/functions/embed/index.ts`
2. Uses `Deno.serve()` pattern (not old oak/express)
3. Reads OPENAI_API_KEY from `Deno.env.get()` (not hardcoded)
4. Uses SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY from env
5. Handles both webhook format (`payload.record`) and direct format
6. Calls OpenAI text-embedding-3-small endpoint
7. Updates global_memory embedding column via Supabase client
8. Returns proper HTTP status codes: 200 success, 400 bad input, 405 method not allowed, 500/502 errors
9. Has idempotency check for existing embeddings
  </verify>
  <done>Embed Edge Function created at supabase/functions/embed/index.ts</done>
</task>

<task type="auto">
  <name>Task 2: Create search Edge Function</name>
  <files>supabase/functions/search/index.ts</files>
  <action>
Create the directory `supabase/functions/search/` and write `index.ts`. This Edge Function accepts a query string, generates its embedding, and calls the `match_memory()` RPC to return semantically similar memory entries.

**Create `supabase/functions/search/index.ts`:**

```typescript
import "jsr:@supabase/functions-js/edge-runtime.d.ts";
import { createClient } from "jsr:@supabase/supabase-js@2";

const supabaseUrl = Deno.env.get("SUPABASE_URL")!;
const supabaseKey = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY")!;
const openaiKey = Deno.env.get("OPENAI_API_KEY")!;

const supabase = createClient(supabaseUrl, supabaseKey);

Deno.serve(async (req) => {
  if (req.method !== "POST") {
    return new Response("Method not allowed", { status: 405 });
  }

  try {
    const body = await req.json();
    const query = body.query;
    const matchCount = body.match_count ?? 5;
    const matchThreshold = body.match_threshold ?? 0.7;

    if (!query || typeof query !== "string") {
      return new Response(
        JSON.stringify({ error: "Missing or invalid query parameter" }),
        { status: 400, headers: { "Content-Type": "application/json" } }
      );
    }

    // Generate embedding for the query
    const embeddingResponse = await fetch(
      "https://api.openai.com/v1/embeddings",
      {
        method: "POST",
        headers: {
          Authorization: `Bearer ${openaiKey}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          model: "text-embedding-3-small",
          input: query,
        }),
      }
    );

    if (!embeddingResponse.ok) {
      const err = await embeddingResponse.text();
      console.error("OpenAI API error:", err);
      return new Response(
        JSON.stringify({ results: [], error: "OpenAI API error" }),
        { status: 200, headers: { "Content-Type": "application/json" } }
      );
    }

    const embeddingData = await embeddingResponse.json();
    const queryEmbedding = embeddingData.data?.[0]?.embedding;

    if (!queryEmbedding) {
      return new Response(
        JSON.stringify({ results: [], error: "No embedding returned" }),
        { status: 200, headers: { "Content-Type": "application/json" } }
      );
    }

    // Call match_memory() RPC
    const { data, error } = await supabase.rpc("match_memory", {
      query_embedding: JSON.stringify(queryEmbedding),
      match_threshold: matchThreshold,
      match_count: matchCount,
    });

    if (error) {
      console.error("match_memory RPC error:", error);
      return new Response(
        JSON.stringify({ results: [], error: error.message }),
        { status: 200, headers: { "Content-Type": "application/json" } }
      );
    }

    return new Response(
      JSON.stringify({ results: data || [] }),
      { status: 200, headers: { "Content-Type": "application/json" } }
    );
  } catch (err) {
    console.error("Search function error:", err);
    return new Response(
      JSON.stringify({ results: [], error: err instanceof Error ? err.message : "Unknown error" }),
      { status: 200, headers: { "Content-Type": "application/json" } }
    );
  }
});
```

**Key design decisions:**
- Always returns HTTP 200 with `{ results: [] }` on errors — the relay expects graceful degradation, not HTTP errors
- Uses `match_memory()` RPC created in Phase 14 (examples/supabase-schema-v2.sql line 243-267)
- Default threshold 0.7, default count 5 — configurable by caller
- No CORS handling needed — only called by Supabase JS client (functions.invoke) which handles auth automatically
  </action>
  <verify>
1. File exists at `supabase/functions/search/index.ts`
2. Uses `Deno.serve()` pattern
3. Reads OPENAI_API_KEY, SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY from env
4. Accepts `{ query, match_count?, match_threshold? }` body
5. Validates query parameter
6. Calls OpenAI text-embedding-3-small to embed the query
7. Calls `supabase.rpc("match_memory", ...)` with the query embedding
8. Returns `{ results: [...] }` on success
9. Returns `{ results: [] }` on any error (graceful degradation)
10. Never returns non-200 HTTP status for operational errors (only 400 for bad input, 405 for wrong method)
  </verify>
  <done>Search Edge Function created at supabase/functions/search/index.ts</done>
</task>

<task type="auto">
  <name>Task 3: Add getRelevantMemory() and integrate in buildPrompt()</name>
  <files>src/relay.ts</files>
  <action>
Add semantic search to the relay by creating `getRelevantMemory()` and integrating its results into `buildPrompt()`.

**3a. Add `getRelevantMemory()` function — insert immediately after `getActiveGoals()` (after line ~414, after the `completeGoal()` function):**

Find the end of the `completeGoal()` function and insert this new function right after it:

```typescript
async function getRelevantMemory(
  query: string
): Promise<Array<{ content: string; type: string; similarity: number }>> {
  if (!supabase) return [];
  try {
    const { data, error } = await supabase.functions.invoke("search", {
      body: { query, match_count: 5, match_threshold: 0.7 },
    });
    if (error) {
      console.warn("Semantic search unavailable:", error.message);
      return [];
    }
    return data?.results || [];
  } catch (e) {
    // Graceful fallback — Edge Functions not deployed or unreachable
    return [];
  }
}
```

**3b. Update `buildPrompt()` to fetch and include semantic results:**

In the `buildPrompt()` function (line ~2648), add a semantic search call and the RELEVANT MEMORIES section.

After the `activeGoals` fetch (line ~2665):
```typescript
const activeGoals = await getActiveGoals();
```

Add:
```typescript

// Semantic search — find memories relevant to the current message
const relevantMemories = await getRelevantMemory(userMessage);
```

Then, after the `activeGoals` display section (after line ~2701, after the goals `.join("\n");` block) and before the threadContext block, add:

```typescript

if (relevantMemories.length > 0) {
  // Deduplicate: filter out memories already shown in facts or goals sections
  const shownContent = new Set([
    ...memoryFacts.map((f) => f.toLowerCase()),
    ...activeGoals.map((g) => g.content.toLowerCase()),
  ]);
  const uniqueRelevant = relevantMemories.filter(
    (m) => !shownContent.has(m.content.toLowerCase())
  );
  if (uniqueRelevant.length > 0) {
    prompt += "\n\nRELEVANT MEMORIES (semantically related to your message):\n";
    prompt += uniqueRelevant
      .map((m) => `- ${m.content} [${m.type}, relevance: ${(m.similarity * 100).toFixed(0)}%]`)
      .join("\n");
  }
}
```

The full insertion point in `buildPrompt()` should be:

1. Soul + time (existing)
2. THINGS I KNOW ABOUT THE USER (existing facts)
3. ACTIVE GOALS (existing goals)
4. **RELEVANT MEMORIES** (new — semantically similar, deduplicated)
5. Thread context (existing)
6. Skill registry (existing)
7. MEMORY INSTRUCTIONS (existing)
8. User message (existing)

**Important:** The `getRelevantMemory()` call is async and adds latency (OpenAI embedding + RPC). To minimize impact, it runs alongside the other async calls. The memory facts and goals are fetched in sequence anyway, so adding one more async call is acceptable. If it times out, the graceful fallback returns [].

**3c. Do NOT add semantic search to heartbeat or cron prompt builders.** The requirement R9 specifies `buildPrompt()` only. Heartbeat prompts are driven by HEARTBEAT.md checklist (not user messages), and cron prompts are driven by scheduled task prompts — neither benefits from querying semantic memory against a task description.
  </action>
  <verify>
1. `getRelevantMemory` function exists in relay.ts after `completeGoal()`
2. It calls `supabase.functions.invoke("search", ...)`
3. It returns `[]` on any error (graceful fallback)
4. `buildPrompt()` calls `getRelevantMemory(userMessage)`
5. RELEVANT MEMORIES section appears in the prompt when results exist
6. Deduplication logic filters out content already in memoryFacts or activeGoals
7. Heartbeat prompt builder is unchanged (no semantic search added)
8. Cron prompt builder is unchanged (no semantic search added)
9. `bun build src/relay.ts --no-bundle 2>&1 | head -20` succeeds with no errors
  </verify>
  <done>getRelevantMemory() added to relay.ts and integrated in buildPrompt() with deduplication and graceful fallback.</done>
</task>

<task type="auto">
  <name>Task 4: Update reference schema and create setup documentation</name>
  <files>examples/supabase-schema-v2.sql, docs/SETUP-SEMANTIC-SEARCH.md</files>
  <action>
Update the reference schema with a comment noting the webhook requirement, and create setup documentation for deploying the Edge Functions and configuring the database webhook.

**4a. Add a comment block to `examples/supabase-schema-v2.sql`** — at the end of the file, after the last `CREATE POLICY` statement, add:

```sql

-- ============================================================
-- SEMANTIC SEARCH SETUP (v1.3 Phase 16)
-- ============================================================
-- The embedding column and match_memory() RPC are defined above.
-- To enable auto-embedding, configure a Database Webhook:
--   1. Deploy the embed Edge Function: supabase functions deploy embed
--   2. In Supabase Dashboard: Database > Webhooks > Create
--      - Name: embed_memory
--      - Table: global_memory
--      - Events: INSERT
--      - Type: Supabase Edge Function
--      - Function: embed
--   3. Set the OPENAI_API_KEY secret: supabase secrets set OPENAI_API_KEY=sk-...
--   4. Deploy the search Edge Function: supabase functions deploy search
--
-- See docs/SETUP-SEMANTIC-SEARCH.md for full instructions.
```

**4b. Create `docs/SETUP-SEMANTIC-SEARCH.md`:**

```markdown
# Semantic Search Setup

Phase 16 of the Claude Telegram Relay adds semantic memory search powered by OpenAI embeddings and Supabase Edge Functions.

## Prerequisites

- Supabase project with Phase 14 migration applied (vector column, match_memory RPC)
- Supabase CLI installed (`npm i -g supabase`)
- OpenAI API key with access to text-embedding-3-small

## 1. Set Supabase Secrets

The OpenAI API key lives exclusively in Supabase Edge Function secrets — it is never added to the relay's `.env` file.

```bash
supabase secrets set OPENAI_API_KEY=sk-your-key-here
```

## 2. Deploy Edge Functions

From the project root:

```bash
supabase functions deploy embed
supabase functions deploy search
```

To verify deployment:

```bash
supabase functions list
```

## 3. Configure Database Webhook

The embed function must be triggered automatically when a new memory is inserted.

### Option A: Supabase Dashboard (Recommended)

1. Go to **Database > Webhooks** in your Supabase Dashboard
2. Click **Create a new webhook**
3. Configure:
   - **Name:** `embed_memory`
   - **Table:** `global_memory`
   - **Events:** `INSERT` only
   - **Type:** Supabase Edge Function
   - **Edge Function:** `embed`
4. Click **Create webhook**

### Option B: SQL Trigger with pg_net

If you prefer version-controlled infrastructure, run this SQL after storing your project URL in vault:

```sql
-- Store project URL in vault (run once)
-- Local: select vault.create_secret('http://api.supabase.internal:8000', 'project_url');
-- Production: select vault.create_secret('https://YOUR-PROJECT.supabase.co', 'project_url');

-- Helper to get project URL from vault
CREATE OR REPLACE FUNCTION util_get_project_url()
RETURNS TEXT
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
DECLARE
  url TEXT;
BEGIN
  SELECT decrypted_secret INTO url
  FROM vault.decrypted_secrets
  WHERE name = 'project_url';
  RETURN url;
END;
$$;

-- Trigger function: POST to embed Edge Function on INSERT
CREATE OR REPLACE FUNCTION trigger_embed_memory()
RETURNS TRIGGER
LANGUAGE plpgsql
SECURITY DEFINER
AS $$
BEGIN
  PERFORM net.http_post(
    url := util_get_project_url() || '/functions/v1/embed',
    headers := jsonb_build_object(
      'Content-Type', 'application/json',
      'Authorization', 'Bearer ' || current_setting('supabase.service_role_key', true)
    ),
    body := jsonb_build_object(
      'id', NEW.id,
      'content', NEW.content,
      'type', NEW.type
    ),
    timeout_milliseconds := 30000
  );
  RETURN NEW;
END;
$$;

CREATE TRIGGER on_global_memory_insert
  AFTER INSERT ON global_memory
  FOR EACH ROW
  EXECUTE FUNCTION trigger_embed_memory();
```

## 4. Test the Setup

### Test embed function:

Insert a test memory and verify the embedding is generated:

```sql
INSERT INTO global_memory (content, type) VALUES ('Test semantic search', 'fact');

-- Wait a few seconds, then check:
SELECT id, content, embedding IS NOT NULL AS has_embedding
FROM global_memory
WHERE content = 'Test semantic search';
```

### Test search function:

```bash
curl -X POST "https://YOUR-PROJECT.supabase.co/functions/v1/search" \
  -H "Authorization: Bearer YOUR-ANON-KEY" \
  -H "Content-Type: application/json" \
  -d '{"query": "test search"}'
```

### Test from relay:

Send a message to the bot. Check the relay logs for:
- `Semantic search unavailable` — Edge Functions not deployed or unreachable (fallback working)
- No warning — semantic search is working

## Graceful Degradation

If Edge Functions are not deployed:
- Memory INSERT/FORGET/GOAL/DONE all work normally
- `getRelevantMemory()` returns an empty array silently
- The RELEVANT MEMORIES section simply doesn't appear in the prompt
- No errors shown to the user

## Backfilling Existing Memories

To generate embeddings for memories that were created before the webhook was configured:

```sql
-- Find memories without embeddings
SELECT id, content FROM global_memory WHERE embedding IS NULL;
```

Then invoke the embed function for each:

```bash
curl -X POST "https://YOUR-PROJECT.supabase.co/functions/v1/embed" \
  -H "Authorization: Bearer YOUR-SERVICE-ROLE-KEY" \
  -H "Content-Type: application/json" \
  -d '{"id": "UUID-HERE", "content": "memory content here"}'
```

Or use a SQL loop with pg_net (see Option B trigger setup above).
```
  </action>
  <verify>
1. `examples/supabase-schema-v2.sql` has the semantic search setup comment block at the end
2. `docs/SETUP-SEMANTIC-SEARCH.md` exists
3. Setup doc covers: secrets, deployment, webhook config (Dashboard + SQL options), testing, graceful degradation, backfilling
4. No new env vars mentioned for the relay .env
5. OPENAI_API_KEY only referenced in Supabase secrets context
  </verify>
  <done>Reference schema updated with setup comments, setup documentation created with Dashboard webhook and SQL trigger options.</done>
</task>

</tasks>

<verification>
Phase 16 verification checks mapped to requirements:

1. **R7 (Auto-Embedding Edge Function):**
   - `supabase/functions/embed/index.ts` exists with Deno.serve pattern
   - Generates OpenAI text-embedding-3-small vectors
   - Updates global_memory embedding column
   - Triggered by database webhook (configured via Dashboard or SQL trigger)
   - OPENAI_API_KEY in Supabase secrets only

2. **R8 (Semantic Search Edge Function):**
   - `supabase/functions/search/index.ts` exists with Deno.serve pattern
   - Generates query embedding via OpenAI
   - Calls match_memory() RPC from Phase 14
   - Returns ranked results with similarity scores

3. **R9 (Semantic Memory in Prompt Context):**
   - `getRelevantMemory(query)` calls search Edge Function via supabase.functions.invoke
   - buildPrompt() appends RELEVANT MEMORIES section
   - Results are deduplicated against existing facts and goals
   - Section appears between goals and thread context

4. **R10 (Graceful Degradation):**
   - getRelevantMemory() catches all errors and returns []
   - Search Edge Function returns { results: [] } on OpenAI/RPC errors (HTTP 200)
   - No RELEVANT MEMORIES section appears when Edge Functions are unavailable
   - All non-semantic features work without Edge Functions

5. **NF1 (No New Env Vars in Relay):**
   - OPENAI_API_KEY lives exclusively in Supabase Edge Function secrets
   - Relay .env is unchanged

6. **NF2 (Single-File Architecture Preserved):**
   - All relay changes in src/relay.ts
   - Edge Functions are separate Supabase deployments (supabase/functions/)
</verification>

<success_criteria>
- `supabase/functions/embed/index.ts` exists and handles webhook INSERT payloads
- `supabase/functions/search/index.ts` exists and returns semantic search results
- `getRelevantMemory()` function exists in relay.ts and calls search Edge Function
- `buildPrompt()` includes RELEVANT MEMORIES section with deduplication
- System functions normally without Edge Functions deployed (graceful degradation)
- No new env vars in relay .env (OPENAI_API_KEY only in Supabase secrets)
- `bun build src/relay.ts --no-bundle` succeeds with no errors
- `docs/SETUP-SEMANTIC-SEARCH.md` documents the full setup process
</success_criteria>

<output>
After completion, create `.planning/phases/16-semantic-search-edge-functions/16-01-SUMMARY.md`
</output>
